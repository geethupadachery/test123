# -*- coding: utf-8 -*-
"""Seekers_StanceDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-oZslwrqjC8tJ5Q2ST0wqAmvcgxdJA-L

##**Stance Detection**

Standard imports:
"""

from nltk.stem import WordNetLemmatizer, SnowballStemmer
stemmer = SnowballStemmer('english')
import nltk
nltk.download('wordnet')

import cloudpickle as cp
from urllib.request import urlopen

import string

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

sw = stopwords.words('english')

#from pydrive.auth import GoogleAuth
#from pydrive.drive import GoogleDrive
#from google.colab import auth
#from oauth2client.client import GoogleCredentials

"""Fetching the model from github:   
Random Forest produced best result 
"""

# import requests, zipfile, io
# def download_url(url, save_path, chunk_size=128):
#     r = requests.get(url)
#     z = zipfile.ZipFile(io.BytesIO(r.content))
#     z.extractall(save_path)

# download_url('https://github.com/jrangu/Datasets/blob/master/randomforest.zip?raw=true', '/content/')

import pickle

"""Loading the pickled model and predicting the score"""

class Seekers_StanceDetection:
  stance_score = {'agree': 0.0,'disagree': 0.8,'discuss':0.3,'unrelated': 1.0 }
  def remove_stop_and_short_words(self,text):
    text = [word.lower() for word in text.split() if (word.lower() not in sw) and (len(word)>3)]
    return " ".join(text)
  
  def lemmatize_stemming(self,text):
    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))
  
  def remove_punctuation(self,text):
    translator = str.maketrans('', '', string.punctuation)
    return text.translate(translator)
  
  def process_data(self,text):
    # print ('Input Text :: ' + text)
    text = self.remove_stop_and_short_words(text)
    #print('Stopwords and short words removed :: ' + text)
    text = self.lemmatize_stemming(text)
    #print('Lemmatized :: ' + text)
    text = self.remove_punctuation(text)
    #print('Punctuation removed :: ' + text)
    return text

  def __init__(self, filename):
    self.model = self.load(filename)

  def load(self, path):
    with open(path, 'rb') as file:
      return pickle.load(file)

  def predict(self, text):
    #loaded_model = pickle.load(open('randomforest.sav', 'rb'))
    #loaded_model = cp.load(urlopen("https://drive.google.com/file/d/1Hs7Ky85bGDsaKZnERXMmQBIXCvRoWoZZ/view?usp=sharing"))
    processedText = self.process_data(text)
    result = loaded_model.predict_proba([processedText])
    predictedStance = loaded_model.predict([processedText])[0]
    if predictedStance == 2:
        result=0.49
    elif predictedStance == 1:
        result=0.11
    else: 
        result=0.8
    return result